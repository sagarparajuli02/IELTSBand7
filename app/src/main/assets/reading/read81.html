<!DOCTYPE html>
<html>
<head>
    <link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
<div class="entry-content" itemprop="text">
    <p style="text-align: center;">It is becoming acceptable again to talk of computers
        performing<br>
        human tasks such as problem-solving and pattern-recognition
    </p>
    <p style="text-align: justify;"><strong>A.</strong>&nbsp;After years in the wilderness, the term
        ‘artificial intelligence’ (AI) seems poised to make a comeback. AI was big in the 1980s but
        vanished in the 1990s. It re-entered public consciousness with the release of Al, a movie
        about a robot boy. This has ignited public debate about AI, but the term is also being used
        once more within the computer industry. Researchers, executives and marketing people are now
        using the expression without irony or inverted commas. And it is not always hype. The term
        is being applied, with some justification, to products that depend on technology that was
        originally developed by AI researchers. Admittedly, the rehabilitation of the term has a
        long way to go, and some firms still prefer to avoid using it. But the fact that others are
        starting to use it again suggests that AI has moved on from being seen as an over-ambitious
        and under-achieving field of research.
    </p>
    <p>
    <center><img class="size-full wp-image-3343 aligncenter" src="81.1.jpg"></center>
    </p><p style="text-align: justify;"><strong>B.</strong>&nbsp;The field was launched, and the
    term ‘artificial intelligence’ coined, at a conference in 1956 by a group of researchers that
    included Marvin Minsky, John McCarthy, Herbert Simon and Alan Newell, all of whom went on to
    become leading figures in the field. The expression provided an attractive but informative name
    for a research programme that encompassed such previously disparate fields as operations
    research, cybernetics, logic and computer science. The goal they shared was an attempt to
    capture or mimic human abilities using machines. That said, different groups of researchers
    attacked different problems, from speech recognition to chess playing, in different ways; AI
    unified the field in name only. But it was a term that captured the public imagination.
</p>
    <p style="text-align: justify;"><strong>C.</strong>&nbsp;Most researchers agree that AI peaked
        around 1985. A public reared on science-fiction movies and excited by the growing power of
        computers had high expectations. For years, AI researchers had implied that a breakthrough
        was just around the corner. Marvin Minsky said in 1967 that within a generation the problem
        of creating’artificial intelligence’ would be substantially solved. Prototypes of
        medical-diagnosis programs and speech recognition software appeared to be making progress.
        It proved to be a false dawn. Thinking computers and household robots failed to materialise,
        and a backlash ensued. `There was undue optimism in the early 1980s; says David Leaky, a
        researcher at Indiana University. ‘Then when people realised these were hard problems, there
        was retrenchment. By the late 1980s, the term AI was being avoided by many researchers, who
        opted instead to align themselves with specific sub-disciplines such as neural networks,
        agent technology, case-based reasoning, and so on.
    </p>
    <p style="text-align: justify;"><strong>D.</strong>&nbsp;Ironically, in some ways AI was a
        victim of its own success. Whenever an apparently mundane problem was solved, such as
        building a system that could land an aircraft unattended, the problem was deemed not to have
        been AI in the first plate. ‘If it works, it can’t be AI; as Dr Leaky characterises it. The
        effect of repeatedly moving the goal-posts in this way was that AI came to refer to
        ‘blue-sky’ research that was still years away from commercialisation. Researchers joked that
        AI stood for `almost implemented’. Meanwhile, the technologies that made it onto the market,
        such as speech recognition, language translation and decision-support software, were no
        longer regarded as AI. Yet all three once fell well within the umbrella of AI research.
    </p>
    <p style="text-align: justify;"><strong>E.</strong><strong>&nbsp;</strong>But the tide may now
        be turning, according to Dr Leake. HNC Software of San Diego, backed by a government agency,
        reckon that their new approach to artificial intelligence is the most powerful and promising
        approach ever discovered. HNC claim that their system, based on a cluster of 30 processors,
        could be used to spot camouflaged vehicles on a battlefield or extract a voice signal from a
        noisy background – tasks humans can do well, but computers cannot. ‘Whether or not their
        technology lives up to the claims made for it, the fact that HNC are emphasising the use of
        AI is itself an interesting development; says Dr Leaky.
    </p>
    <p style="text-align: justify;"><strong>F</strong>&nbsp;Another factor that may boost the
        prospects for AI in the near future is that investors are now looking for firms using clever
        technology, rather than just a clever business model, to differentiate themselves. In
        particular, the problem of information overload, exacerbated by the growth of e-mail and the
        explosion in the number of web pages, means there are plenty of opportunities for new
        technologies to help filter and categorise information – classic AI problems. That may mean
        that more artificial intelligence companies will start to emerge to meet this challenge.
    </p>
    <p style="text-align: justify;"><strong>G</strong>&nbsp;The 1969 film, 2001: A Space Odyssey,
        featured an intelligent computer called HAL 9000. As well as understanding and speaking
        English, HAL could play chess and even learned to lipread. HAL thus encapsulated the
        optimism of the 1960s that intelligent computers would be widespread by 2001. But 2001 has
        been and gone, and there is still no sign of a HAL-like computer. Individual systems can
        play chess or transcribe speech, but a general theory of machine intelligence still remains
        elusive. It may be, however, that the comparison with HAL no longer seems quite so
        important, and AI can now be judged by what it can do, rather than by how well it matches up
        to a 30-year-old science-fiction film. ‘People are beginning to realise that there are
        impressive things that these systems can do; says Dr Leake hopefully.
    </p>
    <hr>
    <p><span style="font-size: 14pt; color: #3366ff;"><strong>Questions 27-31</strong></span>
    </p>
    <p><em>Reading Passage 81 has seven paragraphs,</em><em>&nbsp;</em><strong><em>A-G</em></strong><em>.</em>
    </p>
    <p><em>Which paragraph contains the following information?</em>
    </p>
    <p><em>Write the correct letter&nbsp;<strong>A-G</strong>&nbsp;in
        boxes&nbsp;<strong>27-31</strong>&nbsp;on your answer sheet.</em>
    </p>
    <p><em><strong>NB</strong>&nbsp;You may use any letter more than once.</em>
    </p>
    <p><strong>27.</strong>&nbsp;how AI might have a military impact
    </p>
    <p><strong>28.</strong>&nbsp;the fact that AI brings together a range of separate research areas
    </p>
    <p><strong>29.</strong>&nbsp;the reason why AI has become a common topic of conversation again
    </p>
    <p><strong>30.</strong>&nbsp;how AI could help deal with difficulties related to the amount of
        information available electronically
    </p>
    <p><strong>31.</strong>&nbsp;where the expression AI was first used
    </p>
    <p><span style="font-size: 14pt; color: #3366ff;"><strong>Questions 32-37</strong></span>
    </p>
    <p>Do the following statements agree with the information given in Reading Passage 81?
    </p>
    <p>In boxes&nbsp;<strong>32-37</strong>&nbsp;on your answer sheet, write
    </p>
    <p style="padding-left: 60px;"><strong><em>TRUE&nbsp;</em></strong>&nbsp; &nbsp;if the statement
        agrees with the information
    </p>
    <p style="padding-left: 60px;"><strong><em>FALSE&nbsp;</em></strong>&nbsp; &nbsp;if the
        statement contradicts the information
    </p>
    <p style="padding-left: 60px;"><strong><em>NOT GIVEN</em></strong>&nbsp;&nbsp; &nbsp;if there is
        no information on this
    </p>
    <p><strong>32.</strong>&nbsp;The researchers who launched the field of AI had worked together on
        other projects in the past.
    </p>
    <p><strong>33.</strong>&nbsp;In 1985, AI was at its lowest point.
    </p>
    <p><strong>34.</strong>&nbsp;Research into agent technology was more costly than research into
        neural networks.
    </p>
    <p><strong>35.</strong>&nbsp;Applications of AI have already had a degree of success.
    </p>
    <p><strong>36.</strong>&nbsp;The problems waiting to be solved by AI have not changed since
        1967.
    </p>
    <p><strong>37.</strong>&nbsp;The film 2001: A Space Odyssey reflected contemporary ideas about
        the potential of AI computers.
    </p>
    <p><span style="font-size: 14pt; color: #3366ff;"><strong>Questions 38-40</strong></span>
    </p>
    <p><em>Choose the correct letter,</em><em>&nbsp;</em><strong><em>A, B,
        C</em></strong><strong><em>&nbsp;</em></strong><em>or</em><em>&nbsp;</em><strong><em>D.</em></strong>
    </p>
    <p><em>Write your answers in boxes&nbsp;<strong>38-40</strong>&nbsp;on your answer sheet.</em>
    </p>
    <p><strong>38.</strong><strong>&nbsp;</strong>According to researchers, in the late 1980s there
        was a feeling that
    </p>
    <p style="padding-left: 30px;"><strong>A.</strong> a general theory of AI would never be
        developed.
    </p>
    <p style="padding-left: 30px;"><strong>B.</strong> original expectations of AI may not have been
        justified.
    </p>
    <p style="padding-left: 30px;"><strong>C.</strong> a wide range of applications was close to
        fruition.
    </p>
    <p style="padding-left: 30px;"><strong>D.</strong> more powerful computers were the key to
        further progress.
    </p>
    <p><strong>39.</strong>&nbsp;In Dr Leake’s opinion, the reputation of AI suffered as a result of
    </p>
    <p style="padding-left: 30px;"><strong>A.</strong> changing perceptions.
    </p>
    <p style="padding-left: 30px;"><strong>B.</strong> premature implementation.
    </p>
    <p style="padding-left: 30px;"><strong>C.</strong> poorly planned projects.
    </p>
    <p style="padding-left: 30px;"><strong>D.</strong> commercial pressures.
    </p>
    <p><strong>40.</strong>&nbsp;The prospects for AI may benefit from
    </p>
    <p style="padding-left: 30px;">A. existing AI applications.
    </p>
    <p style="padding-left: 30px;">B. new business models.
    </p>
    <p style="padding-left: 30px;">C. orders from Internet-only companies.
    </p>
    <p style="padding-left: 30px;">D. new investment priorities.
    </p>
    <p>&nbsp;
    </p>
    <p><span style="font-size: 10pt; background-color: #ff9900;"> <strong>Answer:</strong><strong>&nbsp;</strong></span><br>
        <span style="font-size: 10pt; background-color: #ff9900;"> 27. E &nbsp;&nbsp; 28. B &nbsp;&nbsp; 29. A &nbsp;&nbsp; 30. F&nbsp;&nbsp;&nbsp; 31. B&nbsp;&nbsp;&nbsp; 32. NOT GIVEN &nbsp;&nbsp; 33. FALSE&nbsp; &nbsp; &nbsp; 34. NOT GIVEN&nbsp; &nbsp;&nbsp; 35. TRUE &nbsp;&nbsp;&nbsp; 36. FALSE &nbsp;&nbsp;&nbsp; 37.&nbsp; TRUE &nbsp;&nbsp; 38. B &nbsp;&nbsp;&nbsp;&nbsp; 39. A &nbsp;&nbsp; 40. D</span>
    </p>
</div>
</body>
</html>